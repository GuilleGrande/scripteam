# Production Docker Compose Configuration
# For deployment to Hostinger VPS

version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: scripteam-postgres-prod
    environment:
      POSTGRES_DB: scripteam_prod
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backups:/backups
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d scripteam_prod"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: scripteam-redis-prod
    volumes:
      - redis_data:/data
      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf:ro
    command: redis-server /usr/local/etc/redis/redis.conf
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # n8n Workflow Engine
  n8n:
    image: n8nio/n8n:latest
    container_name: scripteam-n8n-prod
    environment:
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=${N8N_AUTH_USER}
      - N8N_BASIC_AUTH_PASSWORD=${N8N_AUTH_PASSWORD}
      - N8N_HOST=${DOMAIN}
      - N8N_PORT=5678
      - N8N_PROTOCOL=https
      - WEBHOOK_URL=https://${DOMAIN}/webhooks/
      - GENERIC_TIMEZONE=Europe/Madrid
      - N8N_LOG_LEVEL=warn
    volumes:
      - n8n_data:/home/node/.n8n
      - ./n8n/workflows:/home/node/.n8n/workflows:ro
      - ./n8n/credentials:/home/node/.n8n/credentials:ro
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:5678/healthz"]
      interval: 60s
      timeout: 30s
      retries: 3
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # API Backend
  api:
    image: ghcr.io/${GITHUB_REPOSITORY}/api:main
    container_name: scripteam-api-prod
    environment:
      - NODE_ENV=production
      - PORT=3000
      - DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD}@postgres:5432/scripteam_prod
      - REDIS_URL=redis://redis:6379
      - N8N_BASE_URL=http://n8n:5678
      - JWT_SECRET=${JWT_SECRET}
      - ELEVENLABS_API_KEY=${ELEVENLABS_API_KEY}
      - PLAYHT_API_KEY=${PLAYHT_API_KEY}
      - HOSTINGER_CDN_URL=${HOSTINGER_CDN_URL}
      - SENTRY_DSN=${SENTRY_DSN}
      - LOG_LEVEL=info
    volumes:
      - upload_data:/app/uploads
      - ./logs:/app/logs
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # GPT-OSS AI Processing
  gpt-oss:
    image: ghcr.io/scripteam/gpt-oss:latest
    container_name: scripteam-gpt-oss-prod
    environment:
      - MODEL_PATH=/models
      - API_PORT=8080
      - MAX_WORKERS=4
      - LOG_LEVEL=info
    volumes:
      - gpt_models:/models
      - ./logs:/app/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 60s
      timeout: 30s
      retries: 3
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Nginx Reverse Proxy
  nginx:
    image: nginx:alpine
    container_name: scripteam-nginx-prod
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/prod.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - upload_data:/var/www/uploads:ro
      - ./nginx/logs:/var/log/nginx
    depends_on:
      - api
      - n8n
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  n8n_data:
    driver: local
  upload_data:
    driver: local
  gpt_models:
    driver: local

networks:
  default:
    name: scripteam-prod-network